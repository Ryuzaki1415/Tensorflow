{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "lDLseSThKRqo"
      },
      "outputs": [],
      "source": [
        "#IMPORTING LIBRARIES\n",
        "#DJ\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Bidirectional"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown --id 108jAePKK4R3BVYBbYJZ32JWUwxeMg20K\n",
        " #DOWNLOAD DATASET"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m2Dum4xtKSwU",
        "outputId": "770b28ae-d2c7-4ef7-c91f-e0a756a6c67a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gdown/cli.py:121: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=108jAePKK4R3BVYBbYJZ32JWUwxeMg20K\n",
            "To: /content/sonnets.txt\n",
            "100% 93.6k/93.6k [00:00<00:00, 91.7MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "SONNETS_FILE = './sonnets.txt'"
      ],
      "metadata": {
        "id": "FvEFqX7uKSyr"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define path for file with sonnets\n",
        "SONNETS_FILE = './sonnets.txt'\n",
        "\n",
        "# Reading the data\n",
        "with open('./sonnets.txt') as f:\n",
        "    data = f.read()\n",
        "\n",
        "# Converting the text to lower case and save as a list\n",
        "corpus = data.lower().split(\"\\n\")\n",
        "\n",
        "print(f\"There are {len(corpus)} lines of sonnets\\n\")\n",
        "print(f\"The first 5 lines look like this:\\n\")\n",
        "for i in range(5):\n",
        "  print(corpus[i])\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "enUL6g6nKS1N",
        "outputId": "f02a42ba-3016-40c7-e772-f88710d34cf6"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 2159 lines of sonnets\n",
            "\n",
            "The first 5 lines look like this:\n",
            "\n",
            "from fairest creatures we desire increase,\n",
            "that thereby beauty's rose might never die,\n",
            "but as the riper should by time decease,\n",
            "his tender heir might bear his memory:\n",
            "but thou, contracted to thine own bright eyes,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(corpus)\n",
        "total_words = len(tokenizer.word_index) + 1  # Here we are tokenizing the corpus"
      ],
      "metadata": {
        "id": "pH0zAOTxKS39"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.texts_to_sequences(corpus[0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jBpDOpGdKS57",
        "outputId": "dcee4e42-d59b-4830-8bf0-ab238b1871ec"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[],\n",
              " [],\n",
              " [58],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [17],\n",
              " [6],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [17],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [6],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [6],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [],\n",
              " [17],\n",
              " [],\n",
              " [],\n",
              " []]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.texts_to_sequences([corpus[0]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7q8OzrjMKS8M",
        "outputId": "03f74b02-f3df-4361-dab9-2748b6da85ae"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[34, 417, 877, 166, 213, 517]]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.texts_to_sequences([corpus[0]])[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EaMRz8RIKS-c",
        "outputId": "cc590343-8ebc-4001-8945-b002a1388ff7"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[34, 417, 877, 166, 213, 517]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def n_gram_seqs(corpus, tokenizer):\n",
        "\tinput_sequences = []\n",
        "                                                              # converting to sequences\n",
        "\tfor line in corpus:\n",
        "\t\ttoken_list = tokenizer.texts_to_sequences([line])[0]\n",
        "\t\tfor i in range(1, len(token_list)):\n",
        "\t\t\tn_gram_sequence = token_list[:i+1]\n",
        "\t\t\tinput_sequences.append(n_gram_sequence)\n",
        "\n",
        "\treturn input_sequences"
      ],
      "metadata": {
        "id": "QxQoHiDiMJqM"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#testing function with a corpus\n",
        "first_example_sequence = n_gram_seqs([corpus[0]], tokenizer)\n",
        "\n",
        "print(\"n_gram sequences for first example look like this:\\n\")\n",
        "first_example_sequence\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wf7-MBR8MJwz",
        "outputId": "a806356b-b635-4845-8735-9af93ad5d1d2"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "n_gram sequences for first example look like this:\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[34, 417],\n",
              " [34, 417, 877],\n",
              " [34, 417, 877, 166],\n",
              " [34, 417, 877, 166, 213],\n",
              " [34, 417, 877, 166, 213, 517]]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Testing  function with a bigger corpus\n",
        "next_3_examples_sequence = n_gram_seqs(corpus[1:4], tokenizer)\n",
        "\n",
        "print(\"n_gram sequences for next 3 examples look like this:\\n\")\n",
        "next_3_examples_sequence"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1efht0FWMJzr",
        "outputId": "46d0ffdc-5b73-468b-ee6a-fd3961f1fba4"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "n_gram sequences for next 3 examples look like this:\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[8, 878],\n",
              " [8, 878, 134],\n",
              " [8, 878, 134, 351],\n",
              " [8, 878, 134, 351, 102],\n",
              " [8, 878, 134, 351, 102, 156],\n",
              " [8, 878, 134, 351, 102, 156, 199],\n",
              " [16, 22],\n",
              " [16, 22, 2],\n",
              " [16, 22, 2, 879],\n",
              " [16, 22, 2, 879, 61],\n",
              " [16, 22, 2, 879, 61, 30],\n",
              " [16, 22, 2, 879, 61, 30, 48],\n",
              " [16, 22, 2, 879, 61, 30, 48, 634],\n",
              " [25, 311],\n",
              " [25, 311, 635],\n",
              " [25, 311, 635, 102],\n",
              " [25, 311, 635, 102, 200],\n",
              " [25, 311, 635, 102, 200, 25],\n",
              " [25, 311, 635, 102, 200, 25, 278]]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply the n_gram_seqs transformation to the whole corpus\n",
        "input_sequences = n_gram_seqs(corpus, tokenizer)\n",
        "\n",
        "# Save max length\n",
        "max_sequence_len = max([len(x) for x in input_sequences])\n",
        "\n",
        "print(f\"n_grams of input_sequences have length: {len(input_sequences)}\")\n",
        "print(f\"maximum length of sequences is: {max_sequence_len}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u-4Lo9frMJ2E",
        "outputId": "fea97c2e-d8dc-49ac-a4ad-0d520995b53d"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "n_grams of input_sequences have length: 15462\n",
            "maximum length of sequences is: 11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# GRADED FUNCTION: pad_seqs\n",
        "def pad_seqs(input_sequences, maxlen):\n",
        "    max_sequence_len = max([len(x) for x in input_sequences])\n",
        "    padded_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre'))\n",
        "\n",
        "    return padded_sequences\n",
        ""
      ],
      "metadata": {
        "id": "6mwjKzRDMVBD"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing function with the n_grams_seq of the first example\n",
        "first_padded_seq = pad_seqs(first_example_sequence, len(first_example_sequence))\n",
        "first_padded_seq"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dvVpx1nvMVDN",
        "outputId": "70842939-77a4-4cac-e8b1-11eea6565980"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  0,   0,   0,   0,  34, 417],\n",
              "       [  0,   0,   0,  34, 417, 877],\n",
              "       [  0,   0,  34, 417, 877, 166],\n",
              "       [  0,  34, 417, 877, 166, 213],\n",
              "       [ 34, 417, 877, 166, 213, 517]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Testing function with the n_grams_seq of the next 3 examples\n",
        "next_3_padded_seq = pad_seqs(next_3_examples_sequence, max([len(s) for s in next_3_examples_sequence]))\n",
        "next_3_padded_seq"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WNndyOz4MXpc",
        "outputId": "64954134-b13e-453f-f1ce-7ef6e4d3cced"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  0,   0,   0,   0,   0,   0,   8, 878],\n",
              "       [  0,   0,   0,   0,   0,   8, 878, 134],\n",
              "       [  0,   0,   0,   0,   8, 878, 134, 351],\n",
              "       [  0,   0,   0,   8, 878, 134, 351, 102],\n",
              "       [  0,   0,   8, 878, 134, 351, 102, 156],\n",
              "       [  0,   8, 878, 134, 351, 102, 156, 199],\n",
              "       [  0,   0,   0,   0,   0,   0,  16,  22],\n",
              "       [  0,   0,   0,   0,   0,  16,  22,   2],\n",
              "       [  0,   0,   0,   0,  16,  22,   2, 879],\n",
              "       [  0,   0,   0,  16,  22,   2, 879,  61],\n",
              "       [  0,   0,  16,  22,   2, 879,  61,  30],\n",
              "       [  0,  16,  22,   2, 879,  61,  30,  48],\n",
              "       [ 16,  22,   2, 879,  61,  30,  48, 634],\n",
              "       [  0,   0,   0,   0,   0,   0,  25, 311],\n",
              "       [  0,   0,   0,   0,   0,  25, 311, 635],\n",
              "       [  0,   0,   0,   0,  25, 311, 635, 102],\n",
              "       [  0,   0,   0,  25, 311, 635, 102, 200],\n",
              "       [  0,   0,  25, 311, 635, 102, 200,  25],\n",
              "       [  0,  25, 311, 635, 102, 200,  25, 278]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Padding the whole corpus\n",
        "input_sequences = pad_seqs(input_sequences, max_sequence_len)\n",
        "\n",
        "print(f\"padded corpus has shape: {input_sequences.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CnNixKCsMXsD",
        "outputId": "241e0f41-41fb-45e7-ca23-5e4e94291798"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "padded corpus has shape: (15462, 11)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# GRADED FUNCTION: features_and_labels\n",
        "def features_and_labels(input_sequences, total_words):\n",
        "    features = input_sequences[:, :-1]\n",
        "    labels = input_sequences[:, -1]\n",
        "    one_hot_labels = to_categorical(labels, num_classes=total_words)\n",
        "\n",
        "    return features, one_hot_labels"
      ],
      "metadata": {
        "id": "0Ew1cAyDMXuT"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "first_features, first_labels = features_and_labels(first_padded_seq, total_words)\n",
        "\n",
        "print(f\"labels have shape: {first_labels.shape}\")\n",
        "print(\"\\nfeatures look like this:\\n\")\n",
        "first_features"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "74OEMSGmMXw0",
        "outputId": "84328abe-8228-488d-a1ff-8ce06dd2dfff"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "labels have shape: (5, 3211)\n",
            "\n",
            "features look like this:\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  0,   0,   0,   0,  34],\n",
              "       [  0,   0,   0,  34, 417],\n",
              "       [  0,   0,  34, 417, 877],\n",
              "       [  0,  34, 417, 877, 166],\n",
              "       [ 34, 417, 877, 166, 213]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Splitting the whole corpus\n",
        "features, labels = features_and_labels(input_sequences, total_words)\n",
        "\n",
        "print(f\"features have shape: {features.shape}\")\n",
        "print(f\"labels have shape: {labels.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w3ae7PirMXzF",
        "outputId": "b2ca44ac-1a7e-4264-b81a-854b457697f8"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features have shape: (15462, 10)\n",
            "labels have shape: (15462, 3211)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyparsing import actions\n",
        "def create_model(total_words, max_sequence_len):\n",
        "\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(total_words, 100, input_length=max_sequence_len-1))\n",
        "    model.add(Bidirectional(LSTM(150)))\n",
        "    model.add(Dense(total_words, activation='softmax'))\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(loss='categorical_crossentropy',\n",
        "                  optimizer='adam',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "\n",
        "    return model\n",
        ""
      ],
      "metadata": {
        "id": "uVHueBtEMVFb"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = create_model(total_words, max_sequence_len)\n",
        "\n",
        "history = model.fit(features, labels, epochs=50, verbose=1)"
      ],
      "metadata": {
        "id": "kZa5aF5_Mkn8"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "acc = history.history['accuracy']\n",
        "loss = history.history['loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'b', label='Training accuracy')\n",
        "plt.title('Training accuracy')\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs, loss, 'b', label='Training Loss')\n",
        "plt.title('Training loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "8mQOirLBNCfM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def download_history():\n",
        "  import pickle\n",
        "  from google.colab import files\n",
        "\n",
        "  with open('history.pkl', 'wb') as f:\n",
        "    pickle.dump(history.history, f)\n",
        "\n",
        "  files.download('history.pkl')\n",
        "\n",
        "download_history()"
      ],
      "metadata": {
        "id": "FiHamfEANChj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seed_text = \"Help me Master Oogway, for I\"\n",
        "next_words = 100\n",
        "\n",
        "for _ in range(next_words):\n",
        "\t# Converting  the text into sequences\n",
        "\ttoken_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "\t# Padding the sequences\n",
        "\ttoken_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
        "\t# Getting the probabilities of predicting a word\n",
        "\tpredicted = model.predict(token_list, verbose=0)\n",
        "\t# Choosing the next word based on the maximum probability\n",
        "\tpredicted = np.argmax(predicted, axis=-1).item()\n",
        "\t# Getting the actual word from the word index\n",
        "\toutput_word = tokenizer.index_word[predicted]\n",
        "\t# Appending to the current text\n",
        "\tseed_text += \" \" + output_word\n",
        "\n",
        "print(seed_text)"
      ],
      "metadata": {
        "id": "NzVk76DvNCj0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "D0Vc1C3rNCmL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4UCnnSGNNCot"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZGbkAl2CNCqz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8u9-ajT8Mkqb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}